{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from quetzal.os.parallel_call import parallel_call_notebook, parallel_call_notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('log/'):\n",
    "    os.makedirs('log/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../../input/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Launcher\n",
    "\n",
    "This notebook automatically launches all operations for a complete model run. One can decide to skip network preparation steps, as they take multiple hours for the region of Germany and the networks are readily included in the repository.\n",
    "\n",
    "Detailed explainations of certain steps can be found in the corresponding notebook. All ASSUMPTIONS are gathered in the `parameters.xls` file. This file also includes scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'workers':2, 'errout_suffix':True, 'sleep':1,'stdout_path':r'log/out.txt', 'stderr_path':r'log/err.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_1 = [1,2,3]\n",
    "param_2 = [50,60]\n",
    "param_3 = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combinations = []\n",
    "n=0\n",
    "for p_1 in param_1:\n",
    "    for p_2 in param_2:\n",
    "        for p_3 in param_3:\n",
    "            param_combinations.append((n,(p_1, p_2, p_3)))\n",
    "            n+=1\n",
    "\n",
    "\n",
    "param_combinations\n",
    "# save them to file\n",
    "param_combinations_dict = dict((str(n),x) for n,x in param_combinations)\n",
    "with open(input_path+'param_combinations_dict.txt', 'w') as f:\n",
    "    print(param_combinations_dict, file=f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each notebook read in param file based on scenario number\n",
    "# configure parameters in notebooks based on file\n",
    "import ast\n",
    "with open(input_path+'param_combinations_dict.txt', \"r\") as file:\n",
    "    param_1, param_2, param_3 = ast.literal_eval(file.read())[\"4\"]\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [str(n) for n, x in param_combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel_call_notebook('001_test_environment.ipynb', arg_list=scenarios, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zone preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zone creation\n",
    "parallel_call_notebook('101_p_create_zones.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('102_OMS_POIs.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access/egress distances to PT services based on networks and census data\n",
    "parallel_call_notebook('Exercise1_network_creation.ipynb', arg_list=scenarios, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scenario in scenarios:\n",
    "#     parallel_call_notebook('Exercise2_OD-LoS-stack.ipynb', arg_list=[scenario], **kwargs)\n",
    "#     parallel_call_notebook('Exercise3_Four_steps.ipynb', arg_list=[scenario], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_call_notebook('Exercise2_OD-LoS-stack.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('Exercise3_Four_steps.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pathfinders and level of service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "Except for the logit model step, all modelling steps require access to the OD volumes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total execution time\n",
    "end = time.time()\n",
    "int(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('quetzal_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3cc4bcfe731f2ee019f386507748d81bde603c38f633cd56cfe2936f38177aa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
